{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e67ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "url = \"https://storage.googleapis.com/kaggle-data-sets/4288635/7379779/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250425%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250425T091509Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=8fda40908efc5cf42cc4e12dbc43bc41db32b52f11a2ad5ccf19f91f7934ed7b0870ae1b44e278c9b0d2d283d0f229c5e61e5188973931fc930288ff71dfd0f31d0834c65ce6edd27dcbc613840ec73d3c248bb47302040a20b36f419da65fbf1b1858ffaaec07fe32d78c4842c38a9a97d40d1d9142f54449fbf4db7e1a8f8bed773d9657552280f74bca2061b9517637465301d9698890339bba5d0c7758bf5a9ec7ac8093be0dd4f9b564baf4b031dbe6a635e39298f2bab9faa6973962111fe8be5490f2537b292eda63c37f17baff8ecfd1f82ae8719e7780efa77ee683c28b52f755b3570f3f318dfc243178ca3498ec3ca70352216f8e53542c7ab8d1\"\n",
    "file_name = \"data.csv\"\n",
    "if os.path.exists(file_name):\n",
    "    print(\"The file already exist\")\n",
    "else:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Downloading file...\")\n",
    "        with open(file_name,\"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Completed\")\n",
    "    else:\n",
    "        print(f\"There is some error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f729fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"shanegerami/ai-vs-human-text\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"AI_Human.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"text\"]\n",
    "text = text[:1000]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import collections\n",
    "from tqdm.notebook import tqdm,trange\n",
    "import pickle\n",
    "\n",
    "class BPETOKENIZER():\n",
    "  def __init__(self):\n",
    "    self.merges = {}\n",
    "    self.pattern = r\"\\p{L}+\\d*|[^\\p{L}\\s]|[\\n\\r]|[\\p{Emoji}]\"\n",
    "\n",
    "  def split_chars(self,raw_text):\n",
    "    vocab = collections.defaultdict(int)\n",
    "    text = re.findall(self.pattern,raw_text)\n",
    "    text = [\" \".join(word) for word in text]\n",
    "    for word in text:\n",
    "      vocab[word] += 1\n",
    "    return vocab,text\n",
    "\n",
    "  def pair_maker(self,vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "      symbols = word.split()\n",
    "      for i in range(len(symbols)-1):\n",
    "        pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "  def pair_merge(self, pair, v_in):\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    return {p.sub(''.join(pair), word): freq for word, freq in v_in.items()}\n",
    "\n",
    "  def train(self,raw_text:str,iteration:int):\n",
    "    vocab,text = self.split_chars(raw_text)\n",
    "    for i in trange(iteration):\n",
    "      pairs = self.pair_maker(vocab)\n",
    "      if not pairs:\n",
    "        print(\"No more pairs to merge\")\n",
    "        break\n",
    "      best_pair = max(pairs,key = pairs.get)\n",
    "      vocab = self.pair_merge(best_pair,vocab)\n",
    "      self.merges[best_pair] = {\"pair\" : \"\".join(best_pair),\"pair_freq_in_data\" : pairs[best_pair]}\n",
    "    return self.merges\n",
    "\n",
    "  def encode(self, raw_text, merge):\n",
    "      vocab, text = self.split_chars(raw_text)\n",
    "      tokens = []\n",
    "\n",
    "      for word in text:\n",
    "          word = word.split()\n",
    "          while len(word) > 1:\n",
    "              pairs = [(word[i], word[i + 1]) for i in range(len(word) - 1)]\n",
    "              pair_found = False\n",
    "\n",
    "              for pair in pairs:\n",
    "                  if pair in merge:\n",
    "                      new_token = \"\".join(pair)\n",
    "                      index = pairs.index(pair)\n",
    "                      word = word[:index] + [new_token] + word[index + 2:]\n",
    "                      pair_found = True\n",
    "                      break\n",
    "\n",
    "              if not pair_found:\n",
    "                  break\n",
    "\n",
    "          tokens.extend(word)\n",
    "\n",
    "      return tokens\n",
    "\n",
    "  def load(self, filepath):\n",
    "      with open(filepath, \"rb\") as file:\n",
    "          data = pickle.load(file)\n",
    "      self.merges = data\n",
    "      print(f\"Loaded tokenizer data from {filepath}\")\n",
    "\n",
    "  def save(self, filepath):\n",
    "    data = {\n",
    "        \"merges\": self.merges\n",
    "    }\n",
    "    with open(filepath, \"wb\") as file:\n",
    "        pickle.dump(data, file)\n",
    "    print(f\"Saved tokenizer data to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = BPETOKENIZER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = bpe.train(\"\".join(text),10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea63acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
